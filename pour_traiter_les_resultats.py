# -*- coding: utf-8 -*-
"""pour traiter les resultats.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1orsUdX-Z1JWxOJOuual2bI-DBYPW7dlk
"""

import tensorflow as tf

from google.colab import drive
drive.mount('/content/drive')


import pandas as pd
import numpy as np
import scipy.io
import matplotlib.pyplot as plt
from matplotlib import patches

import PIL
from PIL import Image
import pylab as pyl


import keras
import sklearn
import h5py
import shutil
import scipy
import cython
import mido
import pytest
import librosa

import librosa.display
import IPython.display



from pathlib import Path

pip install --upgrade librosa

pip install madmom

import madmom
import librosa
import librosa.display

import os
os.chdir('/content/drive/My Drive/Colab Notebooks/')
!pwd
import os.path
from os import path

idSALAMITest = [758, 1484, 342,  1070,  248,  624,  1072,  594,  794,  202,  

868,  702,  442,  1268,  1502,  434,  266,  796,  1088,  20,  654,  980,  856,  

1458,  922,  176,  544,  1134,  306,  1450,  352,  1288,  858,  910,  1186,  

418,  1566,  902,  1212,  1342,  1568,  142,  744,  1306,  1592,  1366,  1098,  

1364,  28,  1078,  1174,  1554,  660,  148,  1142,  1424,  880,  1230,  972,  

180,  156,  854,  1488,  320,  658,  210,  42,  1332,  444,  392,  1616,  1634,  

220,  274,  1354,  1314,  252,  1646,  1284,  1044,  1534,  1576,  950,  586,  

1224,  512,  532,  1100,  304,  558,  430,  314,  938,  1298,  1190,  1462,  

774,  816,  472,  1086,  16,  440,  928,  772,  824,  1636,  1080,  974,  1316,  

1260,  308,  1322,  848,  680,  394,  960,  268,  1480,  1648,  564,  914,  422,  

504,  232,  60,  150,  602,  88,  94,  168,  580,  1478,  850,  1124, 

650,  170,  56,  1590,  1596,  1242,  204,  1626,  92,  738,  944,  1476,  86,  

1282,  1506,  72,  620,  130,  1562,  954,  932,  802,  1340,  506,  1264,  604,  

1250,  254,  1214,  286,  1104,   898,  1102,  1492,  912,  1248,  942,  

408,  478,  26,  1262,  1474,  878,  834,  1542,  52,  810,  1632,  984,  664,  

154,  982,  1066,  548,  1326,  1118,  642,  1638,  894,  104,  1272,  992,  

 962,  776,  1564,  1598,  14,  1290,  842,  1120,  1416,  1618,  524,  

1076,  522,  282,  1170,  874,  1586,  516,  1602,  890,  1112,  830,  948,  

518,  332,  886,  1110,  1378,  508,  1546,  1302,  610,  206,  374,  1152,  

302,  1136]

def trouver_la_liste(beat_frames,annot_frames):
  
  i=0
  liste=[]
  
  
  for k in range (len(annot_frames)): 
    
    annot=annot_frames[k]
    
    while i<=len(beat_frames)-1 and beat_frames[i]<=annot:
      i=i+1
      
    if (i-1)<=len(beat_frames)-1  and  beat_frames[i-1]<=annot:
      liste.append(i-1)
      i=i+1
    else:
      i=i+1
 
  return(liste)

import csv
  
for i in idSALAMITest:
  
  val=i
  y,sr=librosa.load('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI/'+str(i)+'.mp3')
  proc = madmom.features.downbeats.DBNDownBeatTrackingProcessor(beats_per_bar=[3, 4], fps=100)
  act = madmom.features.downbeats.RNNDownBeatProcessor()(y)
  estimated = proc(act)
  beats = estimated[:,0]
  beats_frames=librosa.core.time_to_frames(beats, sr=sr*2)
  downbeats = beats[estimated[:,1]==1]
  downbeats_frames=librosa.core.time_to_frames(downbeats, sr=sr*2)
  
  chromagram = librosa.feature.chroma_cqt(y=y,
                                        sr=sr)
  
  #beats_frames=np.insert(beats_frames,0, 0)
  #beats_frames=np.append(beats_frames,len(chromagram.T)-1)
  
  
  if 0 not in downbeats_frames :
    downbeats_frames=np.insert(downbeats_frames,0, 0)
  if (len(chromagram.T)-1) not in downbeats_frames :
    downbeats_frames=np.append(downbeats_frames,len(chromagram.T)-1)
  
  
  if path.exists('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI_annotations/annotations/'+str(i)+'/parsed/textfile1_functions.txt'):
    txt1 = Path('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI_annotations/annotations/'+str(i)+'/parsed/textfile1_functions.txt').read_text()
    for t in txt1:
      if t!='0' and t!='1' and t!='2' and t!='3' and t!='4' and t!='5' and t!='6' and t!='7' and t!='8' and t!='9' and t!='.':
        txt1 = txt1.replace(t,' ')
    annot_s1=txt1.split()
    annot_sec1=list(map(float, annot_s1))
    annot_frames1=librosa.core.time_to_frames(annot_sec1, sr=sr)
    liste1=trouver_la_liste(downbeats_frames,annot_frames1)
    
  else:
    liste1=[]
  
  if path.exists('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI_annotations/annotations/'+str(i)+'/parsed/textfile2_functions.txt'):
    txt2 = Path('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI_annotations/annotations/'+str(i)+'/parsed/textfile2_functions.txt').read_text()   
    for t in txt2:
      if t!='0' and t!='1' and t!='2' and t!='3' and t!='4' and t!='5' and t!='6' and t!='7' and t!='8' and t!='9' and t!='.':
        txt2 = txt2.replace(t,' ')
    annot_s2=txt2.split()
    annot_sec2=list(map(float, annot_s2))
    annot_frames2=librosa.core.time_to_frames(annot_sec2, sr=sr)
    liste2=trouver_la_liste(downbeats_frames,annot_frames2)
    
  else:
    liste2=[] 
    
  listefusion=liste1
  for i in range (len(liste2)):
    if liste2[i] not in liste1:
      listefusion.append(liste2[i])  
      
  listefusion=sorted(listefusion) 
  
  
  beatsfusion=[]
  for i in range(len(listefusion)):
    beatsfusion.append(downbeats_frames[listefusion[i]])
  
  
  listefusion_times=librosa.core.frames_to_time(beatsfusion, sr=sr)
  col1=listefusion_times[0:len(listefusion_times)-1]
  col2=listefusion_times[1:len(listefusion_times)]
  
  
  fichier='/content/drive/My Drive/Colab Notebooks/Results for downbeatsync/times_th/'+str(val)+'.csv'
  file=open(fichier,'w')
  writer=csv.writer(file,delimiter=',')
  fin=len(col1)
  for i in range(fin):
    writer.writerow((col1[i],col2[i]))
    
  file.close()

pip install mir_eval

import mir_eval

y=mir_eval.io.load_intervals('test1.csv',',')


val=1648
ref_intervals = mir_eval.io.load_intervals('/content/drive/My Drive/Colab Notebooks/Results for beatsync/times_th/'+str(val)+'.csv',',')
est_intervals = mir_eval.io.load_intervals('/content/drive/My Drive/Colab Notebooks/Results for beatsync/times/'+str(val)+'.csv',',')

dicoresults = {};

for i in range(len(idSALAMITest)):
  
  val=idSALAMITest[i]
  
  ref_intervals = mir_eval.io.load_intervals('/content/drive/My Drive/Colab Notebooks/Results for beatsync/times_th/'+str(val)+'.csv',',')
  est_intervals = mir_eval.io.load_intervals('/content/drive/My Drive/Colab Notebooks/Results for beatsync/times_melspec/'+str(val)+'.csv',',')
  
  P, R, F = mir_eval.segment.detection(ref_intervals,
                                     est_intervals,
                                     window=10)
  dicoresults[val]=[P,R,F]

dicoresults

import pickle

pickle.dump(dicoresults, open('/content/drive/My Drive/Colab Notebooks/Results for beatsync/results_melspect_beatsync_3sec', 'wb'))

dicoresults = pickle.load(open('/content/drive/My Drive/Colab Notebooks/Results for beatsync/results_melspect_beatsync_3sec', 'rb'))

moy_P=0
moy_R=0
moy_F=0


for i in range(len(idSALAMITest)):
  
  val=idSALAMITest[i]
  moy_P=moy_P+dicoresults[val][0]
  moy_R=moy_R+dicoresults[val][1]
  moy_F=moy_F+dicoresults[val][2]

dico_moyenneresults=[moy_F/len(idSALAMITest),moy_P/len(idSALAMITest),moy_R/len(idSALAMITest)]

dico_moyenneresults

!pip install --upgrade -q gspread 
!pip install gspread-dataframe

import gspread
from gspread_dataframe import get_as_dataframe, set_with_dataframe

from google.colab import auth 
auth.authenticate_user()
from oauth2client.client import GoogleCredentials 
gc=gspread.authorize(GoogleCredentials.get_application_default())

sheet1=gc.open_by_url('https://docs.google.com/spreadsheets/d/1f10k30xM_gE0wqUNnmQY3YSWhIG9GslLkpR6XZFeqls/edit?usp=sharing')

"""ou:"""

sheet1=gc.open_by_url('https://docs.google.com/spreadsheets/d/1iXcUnMCrjMwQt68WGkYuoV7sybldWFmua88HL_FnN3Q/edit#gid=315883912')

sheet1=gc.open_by_url('https://docs.google.com/spreadsheets/d/13YFyGjUig5SUd3_8VgFei2Yi-aye0-gFwtNFdPCOuJo/edit#gid=1687365834')

sheet1=gc.open_by_url('https://docs.google.com/spreadsheets/d/14y_Qs6Gt0FsH27G9Esi3g0rPHZ3ekzYg8CUjfpP2i6U/edit#gid=1586769586')

ws=sheet1.worksheet('resultsformelspectrosonly_lastversion')

"""ou:"""

ws=sheet1.worksheet('resultsforSSMbeatsync')

ws=sheet1.worksheet('resultsSSMwithoutdownbeatsync')

ws=sheet1.worksheet('resultsSSMwithdownbeatsync')

file=get_as_dataframe(ws)


segment=[]

for i in range(len(file)):
  if file["Predictions"][i]=="Segment":
    segment.append(file["Filename"][i])

segment

segments=pd.DataFrame({"Filename":segment})
segments.to_csv("/content/drive/My Drive/Colab Notebooks/Results for downbeatsync/segments_melspectrogonly.csv",index=False)

"""ou:"""

segments=pd.DataFrame({"Filename":segment})
segments.to_csv("/content/drive/My Drive/Colab Notebooks/Results for downbeatsync/segments_SSMwithoutdownbeatsync.csv",index=False)

segments=pd.DataFrame({"Filename":segment})
segments.to_csv("/content/drive/My Drive/Colab Notebooks/Results for downbeatsync/segments_SSMwithdownbeatsync.csv",index=False)

import csv
  
for j in idSALAMITest:
  
  val=j
  sheet2=gc.open_by_url('https://docs.google.com/spreadsheets/d/1RKiZkAdsefTpd1ILZcD5tN3BTyahNr3MICPu3znvO2A/edit#gid=510240533')
  ws=sheet2.worksheet('segments_SSMwithdownbeatsync')
  file=get_as_dataframe(ws)
  
  segment=[]
  for i in range(len(file)):
      
    if "Test/SSM_sousmatrice"+str(j)+"_" in file["Filename"][i]:
      t="Test/SSM_sousmatrice"+str(j)+"_"
      t2=".jpeg"
      txt1 = (file["Filename"][i]).replace(t,' ')
      txt1 = txt1.replace(t2,' ')
      segment.append(int(txt1))
    if "Test/SSM_segment_sousmatrice"+str(j)+"_" in file["Filename"][i]:
      t3="Test/SSM_segment_sousmatrice"+str(j)+"_"
      t2=".jpeg"
      txt2 = (file["Filename"][i]).replace(t3,' ')
      txt2 = txt2.replace(t2,' ')
      segment.append(int(txt2))
    
    
  segments=pd.DataFrame({"Filename":segment})
  segments.to_csv("/content/drive/My Drive/Colab Notebooks/Results for downbeatsync/segments_SSM_with/"+str(j)+".csv",index=False)
  fichier="/content/drive/My Drive/Colab Notebooks/Results for downbeatsync/segments_SSM_with/"+str(j)+".csv"
  file=open(fichier,'r')
  reader=csv.reader(file)
  
  l=list(reader)
  l=l[1:len(l)]
  
  
  liste=[]
  for i in range (len(l)):
  
    liste.append(int(l[i][0]))
  
  
  y,sr=librosa.load('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI/'+str(j)+'.mp3')
  proc = madmom.features.downbeats.DBNDownBeatTrackingProcessor(beats_per_bar=[3, 4], fps=100)
  act = madmom.features.downbeats.RNNDownBeatProcessor()(y)
  estimated = proc(act)
  beats = estimated[:,0]
  beats_frames=librosa.core.time_to_frames(beats, sr=sr*2)


  chromagram = librosa.feature.chroma_cqt(y=y,
                                        sr=sr)
  
  beats_frames=np.insert(beats_frames,0, 0)
  beats_frames=np.append(beats_frames,len(chromagram.T)-1)

  liste=sorted(liste) 
  
  beatsfusion=[]
  for i in range(len(liste)):
      beatsfusion.append(beats_frames[liste[i]])


  liste_times=librosa.core.frames_to_time(beatsfusion, sr=sr)
  
  
  if len(liste_times)>1:
    col1=liste_times[0:len(liste_times)-1]
    col2=liste_times[1:len(liste_times)]
    
    fichier='/content/drive/My Drive/Colab Notebooks/Results for downbeatsync/times_SSM_with/'+str(val)+'.csv'
    file=open(fichier,'w')
    writer=csv.writer(file,delimiter=',')
    fin=len(col1)
    for i in range(fin):
      writer.writerow((col1[i],col2[i]))
    
    file.close() 
    
    
  if len(liste_times)==1:
    l=[0]
    l.append(liste_times[0])
    col1=l[0:len(l)-1]
    col2=l[1:len(l)]
    
    fichier='/content/drive/My Drive/Colab Notebooks/Results for downbeatsync/times_SSM_with/'+str(val)+'.csv'
    file=open(fichier,'w')
    writer=csv.writer(file,delimiter=',')
    fin=len(col1)
    for i in range(fin):
      writer.writerow((col1[i],col2[i]))
    
    file.close()
