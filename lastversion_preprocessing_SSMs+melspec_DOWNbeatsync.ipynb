{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lastversion_preprocessing_SSMs+melspec_DOWNbeatsync.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xpWLqFaL1OsE","colab_type":"code","outputId":"f6317d47-c053-4f17-ece5-fbda75159c06","executionInfo":{"status":"ok","timestamp":1565196359463,"user_tz":-120,"elapsed":1255,"user":{"displayName":"Amélie Soler","photoUrl":"https://lh3.googleusercontent.com/-pdHPhDuCP78/AAAAAAAAAAI/AAAAAAAAAPs/ku-rDGvv1vY/s64/photo.jpg","userId":"15833420636978628272"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","import scipy.io\n","import matplotlib.pyplot as plt\n","from matplotlib import patches\n","\n","from PIL import Image\n","import pylab as pyl\n","\n","import tensorflow as tf\n","import keras\n","import sklearn\n","import h5py\n","import shutil\n","import scipy\n","import cython\n","import mido\n","import pytest\n","import six\n","import librosa\n","\n","import IPython.display\n","\n","from pathlib import Path"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LAbyMzhG19hE","colab_type":"code","outputId":"8e685df5-a299-457b-e5a3-04db8ce7bb5e","executionInfo":{"status":"ok","timestamp":1565196368408,"user_tz":-120,"elapsed":6406,"user":{"displayName":"Amélie Soler","photoUrl":"https://lh3.googleusercontent.com/-pdHPhDuCP78/AAAAAAAAAAI/AAAAAAAAAPs/ku-rDGvv1vY/s64/photo.jpg","userId":"15833420636978628272"}},"colab":{"base_uri":"https://localhost:8080/","height":277}},"source":["pip install --upgrade librosa"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: librosa in /usr/local/lib/python3.6/dist-packages (0.7.0)\n","Requirement already satisfied, skipping upgrade: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n","Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.3.0)\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.16.4)\n","Requirement already satisfied, skipping upgrade: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n","Requirement already satisfied, skipping upgrade: soundfile>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.10.2)\n","Requirement already satisfied, skipping upgrade: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.8)\n","Requirement already satisfied, skipping upgrade: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.21.3)\n","Requirement already satisfied, skipping upgrade: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.2)\n","Requirement already satisfied, skipping upgrade: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.12.0)\n","Requirement already satisfied, skipping upgrade: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.4.0)\n","Requirement already satisfied, skipping upgrade: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.29.0)\n","Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa) (1.12.3)\n","Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.19)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xDRcSyp_2H3b","colab_type":"code","outputId":"5afc7509-00bf-4587-948f-45ca57041e4c","executionInfo":{"status":"ok","timestamp":1565196372273,"user_tz":-120,"elapsed":9499,"user":{"displayName":"Amélie Soler","photoUrl":"https://lh3.googleusercontent.com/-pdHPhDuCP78/AAAAAAAAAAI/AAAAAAAAAPs/ku-rDGvv1vY/s64/photo.jpg","userId":"15833420636978628272"}},"colab":{"base_uri":"https://localhost:8080/","height":110}},"source":["!pip install madmom"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: madmom in /usr/local/lib/python3.6/dist-packages (0.16.1)\n","Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from madmom) (1.3.0)\n","Requirement already satisfied: numpy>=1.13.4 in /usr/local/lib/python3.6/dist-packages (from madmom) (1.16.4)\n","Requirement already satisfied: mido>=1.2.8 in /usr/local/lib/python3.6/dist-packages (from madmom) (1.2.9)\n","Requirement already satisfied: cython>=0.25 in /usr/local/lib/python3.6/dist-packages (from madmom) (0.29.13)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1J2Hd6r44ND_","colab_type":"code","colab":{}},"source":["import madmom\n","import librosa\n","import librosa.display"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zLaLoBn4QOC","colab_type":"code","outputId":"4b81796d-3509-46ae-d608-7db28bff8b86","executionInfo":{"status":"ok","timestamp":1565196374416,"user_tz":-120,"elapsed":6961,"user":{"displayName":"Amélie Soler","photoUrl":"https://lh3.googleusercontent.com/-pdHPhDuCP78/AAAAAAAAAAI/AAAAAAAAAPs/ku-rDGvv1vY/s64/photo.jpg","userId":"15833420636978628272"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/')\n","!pwd\n","import os.path\n","from os import path"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XtO0p-dn41Li","colab_type":"code","colab":{}},"source":["#ID of SALAMI files for train set\n","\n","idSALAMITrain = [792, 734,  1652,  636,  424,  790,  1068,  754,  1368,  836,  1528,  616,  412,  \n","\n","1382,  838,  638,  348,  1296,  1446,  634,  666,  1160,  1432,  1184,  778,  \n","\n","38,  1122,  640,  1182,  578,  1114,  184,  370,  1536,  526,  1444,  158,  \n","\n","1614,  324,  1518,  1208,  630,  1352,  1276,  298,  1622,  1356,  1372,  476,  \n","\n","1640,  1180,  466,  644,  1522,  588,  656,  10,  844,  1358,  276,  1042,  46,  \n","\n","892,  44,  1526,  1436,  870,  362,  562,  328,  996,  1400,  364,  692,  1200,  \n","\n","876,  1162,  1448,  1204,  752,  542,  1336,  1324,  600,  368,  720,  214,  \n","\n","336,  1106,  188,  414,  1392,  1548,  730,  1574,  1148,  698,  970,  1494,  6,  \n","\n","120,  1370,  494,  800,  1496,  820,  1116,  700,  1510,  242,  1210,  1650,  98,  \n","\n","340,  608,  1172,  612,  678,  212,  486,  1082,  236,  318,  1482,  8,  622,  \n","\n","1580,  400,  1328,  1498,  1096,  1252,  736,  190,  164,  1270,  1216,  1312,  \n","\n","1540,  1512,  436,  366,  140,  584,  480,  32,  1572,  24,  934,  58,  334,  \n","\n","146,  1304,  632,  492,  920,  1220,  1376,  1278,  1504,  1350,  474,  798,  \n","\n","326,  1612,  350,  1226,  1396,  1084,  1520,  1560,  402,  1188,  388,  958,  \n","\n","978,  1360,  446,  662,  310,  546,  12,  1454,  258,  846,  450,  1578,  550,  \n","\n","294,  296,  1456,  404,  1570,  896,  68,  354,  534,  710,  244,  30,  568,  \n","\n","852,  132,  1380,  234,  570,  946,  748,  1166,  1422,  448,  1418,  1406, \n","\n","460,  1344,  1408,  162,  596,  770,  806,  862,  4,  410,  1310,  112,  34,  \n","\n","964,  1460,  1608,  36,  1154,  1128,  726,  260,  676,  924,  1330,  1238,  \n","\n","278,  648,  1628,  598,  1390,  1624,  528,  406,  1420,  750,  740,  1388,  \n","\n","756,  1582,  916,  386,  1412,  272,  1300,  1074,  1530,  228,  488,  152,  \n","\n","1394,  1584,  114,  828,  360,  582,  1374,  1514,  490,  1164,  498,  724,  \n","\n","762,  108,  428,  714,  786,  1146,  186,  1286,  372,  782,  1150,  1470,  940,  \n","\n","54,  808,  696,  358,  728,  1130] \n","\n","\n","\n","#ID of SALAMI files for validation set\n","\n","idSALAMIVal =  [746,  382,  956,  788,  832,  716,  116,  1158,  1490,  768,  \n","\n","166,  78,  312,  760,  1386,  900,  1254,  812,  814,  860,  1090,  378,  1132,  \n","\n","646,  614,  540,  1308,  1516,  882,  742,  930,  22,  864,  1156,  484,  818,  \n","\n","628,  110,  462,  1206,  866,  1362,  1428,  510,  826,  652,  420] \n","\n","\n","\n"," \n","\n","#ID of SALAMI files for test set\n","\n","idSALAMITest = [1626,  92,  738,  944,  1476,  86,  \n","\n","1282,  1506,  72,  620,  130,  1562,  954,  932,  802,  1340,  506,  1264,  604,  \n","\n","1250,  254,  1214,  286,  1104,  118,  898,  1102,  1492,  912,  1248,  942,  \n","\n","408,  478,  26,  1262,  1474,  878,  834,  1542,  52,  810,  1632,  984,  664,  \n","\n","154,  982,  1066,  548,  1326,  1118,  642,  1638,  894,  104,  1272,  992,  \n","\n","218,  962,  776,  1564,  1598,  14,  1290,  842,  1120,  1416,  1618,  524,  \n","\n","1076,  522,  282,  1170,  874,  1586,  516,  1602,  890,  1112,  830,  948,  \n","\n","518,  332,  886,  1110,  1378,  508,  1546,  1302,  610,  206,  374,  1152,  \n","\n","302,  1136]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"appqCAZzO9nX","colab_type":"code","colab":{}},"source":["def trouver_la_liste(downbeats_frames,annot_frames):\n","  \n","  i=0\n","  liste=[]\n","  \n","  #trouver le premier annot sup ou egal au premier downbeat et apres ok pour faire tous les cas!\n","  \n","  for k in range (len(annot_frames)): \n","    \n","    annot=annot_frames[k]\n","    \n","    while i<=len(downbeats_frames)-1 and downbeats_frames[i]<=annot:\n","      i=i+1\n","      \n","    if (i-1)<=len(downbeats_frames)-1 and  downbeats_frames[i-1]<=annot:\n","      liste.append(i-1)\n","      i=i+1\n","    else: \n","      i+1\n"," \n","  return(liste)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Dv-FA1-8saf","colab_type":"code","colab":{}},"source":["def how_to_group_dico_mfcc(downbeats_frames,dico ):\n","  \n","  l_how_to_group=[]\n","  k=0\n","  i=0\n","  Z=np.zeros((13))\n","  dico=dico.T\n","\n","  \n","  beats_division=beats_frames.tolist().index(downbeats_frames[2])-beats_frames.tolist().index(downbeats_frames[1])\n","\n","  \n","  if beats_division==4:\n","    while k<=(len(dico)-1):\n","      M=dico[k]\n","      if k==(len(dico)-1):\n","        M=np.concatenate((M,Z), axis=0)\n","        M=np.concatenate((M,Z), axis=0)\n","        M=np.concatenate((M,Z), axis=0) \n","      else:\n","        if k+1==(len(dico)-1):\n","          M=np.concatenate((M,dico[k+1]), axis=0)\n","          M=np.concatenate((M,Z), axis=0)\n","          M=np.concatenate((M,Z), axis=0)\n","        else:\n","          M=np.concatenate((M,dico[k+1]), axis=0)\n","          if k+2==(len(dico)-1):\n","            M=np.concatenate((M,dico[k+2]), axis=0)\n","            M=np.concatenate((M,Z), axis=0)\n","          else:\n","            M=np.concatenate((M,dico[k+2]), axis=0)\n","            M=np.concatenate((M,dico[k+3]), axis=0)\n","    \n","      k=k+4\n","      l_how_to_group.append(M)\n","      i=i+1\n","      \n","    \n","  if beats_division==3:\n","    while k<=(len(dico)-1):\n","    \n","      M=dico[k]\n","      if k==(len(dico)-1):\n","        M=np.concatenate((M,Z), axis=0)\n","        M=np.concatenate((M,Z), axis=0)\n","      else:\n","        if k+1==(len(dico)-1):\n","          M=np.concatenate((M,dico[k+1]), axis=0)\n","          M=np.concatenate((M,Z), axis=0)\n","        else:\n","          M=np.concatenate((M,dico[k+1]), axis=0)\n","          M=np.concatenate((M,dico[k+2]), axis=0)\n","      \n","      k=k+3\n","      l_how_to_group.append(M)\n","      i=i+1\n","      \n","    \n","  return (l_how_to_group)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4nzqXieK7aZ","colab_type":"code","colab":{}},"source":["def how_to_group_chromas(downbeats_frames,dico ):\n","  \n","  l_how_to_group=[]\n","  k=0\n","  i=0\n","  dico=dico.T\n","  Z=np.zeros((12))\n","\n","  beats_division=beats_frames.tolist().index(downbeats_frames[2])-beats_frames.tolist().index(downbeats_frames[1])\n","\n","  if beats_division==4:\n","    while k<=(len(dico)-1):\n","      M=dico[k]\n","      if k==(len(dico)-1):\n","        M=np.concatenate((M,Z), axis=0)\n","        M=np.concatenate((M,Z), axis=0)\n","        M=np.concatenate((M,Z), axis=0) \n","      else:\n","        if k+1==(len(dico)-1):\n","          M=np.concatenate((M,dico[k+1]), axis=0)\n","          M=np.concatenate((M,Z), axis=0)\n","          M=np.concatenate((M,Z), axis=0)\n","        else:\n","          M=np.concatenate((M,dico[k+1]), axis=0)\n","          if k+2==(len(dico)-1):\n","            M=np.concatenate((M,dico[k+2]), axis=0)\n","            M=np.concatenate((M,Z), axis=0)\n","          else:\n","            M=np.concatenate((M,dico[k+2]), axis=0)\n","            M=np.concatenate((M,dico[k+3]), axis=0)\n","    \n","      k=k+4\n","      l_how_to_group.append(M)\n","      i=i+1\n","      \n","    \n","  if beats_division==3:\n","    while k<=(len(dico)-1):\n","    \n","      M=dico[k]\n","      if k==(len(dico)-1):\n","        M=np.concatenate((M,Z), axis=0)\n","        M=np.concatenate((M,Z), axis=0)\n","      else:\n","        if k+1==(len(dico)-1):\n","          M=np.concatenate((M,dico[k+1]), axis=0)\n","          M=np.concatenate((M,Z), axis=0)\n","        else:\n","          M=np.concatenate((M,dico[k+1]), axis=0)\n","          M=np.concatenate((M,dico[k+2]), axis=0)\n","      \n","      k=k+3\n","      l_how_to_group.append(M)\n","      i=i+1\n","      \n","   \n","    \n","  return (l_how_to_group)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBsHtiBAKETa","colab_type":"code","outputId":"5646370f-e534-45bc-e2e1-2f66e237d886","executionInfo":{"status":"ok","timestamp":1565196390169,"user_tz":-120,"elapsed":4218,"user":{"displayName":"Amélie Soler","photoUrl":"https://lh3.googleusercontent.com/-pdHPhDuCP78/AAAAAAAAAAI/AAAAAAAAAPs/ku-rDGvv1vY/s64/photo.jpg","userId":"15833420636978628272"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["!pip install essentia"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: essentia in /usr/local/lib/python3.6/dist-packages (2.1b5.dev707)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from essentia) (1.16.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from essentia) (1.12.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from essentia) (3.13)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j-HdkrSLKBTW","colab_type":"code","colab":{}},"source":["  import essentia, essentia.standard as ess\n","\n","  hamming_window = ess.Windowing(type='hamming')\n","  spectrum = ess.Spectrum()  # we just want the magnitude spectrum\n","  mfcc = ess.MFCC(numberCoefficients=13)\n","  frame_sz = 1024\n","  hop_sz = 512\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnrTD8tHqZyx","colab_type":"code","colab":{}},"source":["def decoupe_beats_in4parts(beats_frames):\n","\n","  l=[]\n","  for k in range (len(beats_frames)-1): \n","    \n","    milieu1=round((beats_frames[k+1]-beats_frames[k])/2)\n","    sub_beat2=beats_frames[k]+milieu1\n","    milieu2=round((sub_beat2-beats_frames[k])/2)\n","    sub_beat1=beats_frames[k]+milieu2\n","    milieu3=round((beats_frames[k+1]-sub_beat2)/2)\n","    sub_beat3=sub_beat2+milieu3\n","    \n","    l.append(beats_frames[k])\n","    l.append(sub_beat1)\n","    l.append(sub_beat2)\n","    l.append(sub_beat3)\n","  \n","  diff=sub_beat2-sub_beat1\n","  l.append(beats_frames[len(beats_frames)-1])  \n","  l.append(beats_frames[len(beats_frames)-1]+diff)\n","  l.append(beats_frames[len(beats_frames)-1]+2*diff)\n","  l.append(beats_frames[len(beats_frames)-1]+3*diff)\n","  \n","  l=[ int(x) for x in l ]\n","  l=np.array(l)  \n","  return l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u6T5LdnSqnN8","colab_type":"code","colab":{}},"source":["def get_dico_peaks(beats_frames, peaks,o_env):\n","  i=0\n","  somme=0\n","  dico_peak={}\n","  beat_old=0\n","\n","  for k in range (len(beats_frames)): \n","    beat=beats_frames[k]\n","    while i<=len(peaks)-1 and peaks[i]>=beat_old and peaks[i]<beat:\n","      somme=somme+o_env[peaks[i]]\n","      i=i+1\n","    dico_peak[k]=somme\n","    somme=0\n","    beat_old=beat\n","    \n","  \n","  if i<=len(peaks)-1 and peaks[i]>=beat_old:\n","    for m in range (i,len(peaks)):\n","      somme=somme+o_env[peaks[m]]\n","    dico_peak[k+1]=somme\n","    \n","  else:\n","    dico_peak[k+1]=0\n"," \n","    \n","  return dico_peak"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x84Bkwx3rjNS","colab_type":"code","colab":{}},"source":["def how_to_group_dico_subdiv4(downbeats_frames, dico_peak):\n","  \n","  dico_how_to_group={}\n","  k=1\n","  liste=[]\n","  i=0\n","\n","  beats_division=beats_frames.tolist().index(downbeats_frames[2])-beats_frames.tolist().index(downbeats_frames[1])\n","\n","  if beats_division==4:\n","    while (k+3)<=(len(dico_peak)-1):\n","    \n","      liste.append(dico_peak[k])\n","      liste.append(dico_peak[k+1])\n","      liste.append(dico_peak[k+2])\n","      liste.append(dico_peak[k+3])\n","      \n","      if (k+3)==(len(dico_peak)-1):\n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        \n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        \n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        \n","      \n","      else:\n","              \n","        if (k+7)==(len(dico_peak)-1):\n","          liste.append(dico_peak[k+4])\n","          liste.append(dico_peak[k+5])\n","          liste.append(dico_peak[k+6])\n","          liste.append(dico_peak[k+7])\n","          \n","          liste.append(0)\n","          liste.append(0)\n","          liste.append(0)\n","          liste.append(0)\n","          \n","          liste.append(0)\n","          liste.append(0)\n","          liste.append(0)\n","          liste.append(0)\n","          \n","        else:\n","          liste.append(dico_peak[k+4])\n","          liste.append(dico_peak[k+5])\n","          liste.append(dico_peak[k+6])\n","          liste.append(dico_peak[k+7])\n","          \n","          if (k+11)==(len(dico_peak)-1):\n","            \n","            liste.append(dico_peak[k+8])\n","            liste.append(dico_peak[k+9])\n","            liste.append(dico_peak[k+10])\n","            liste.append(dico_peak[k+11])\n","          \n","            liste.append(0)\n","            liste.append(0)\n","            liste.append(0)\n","            liste.append(0)\n","            \n","          else:\n","            liste.append(dico_peak[k+8])\n","            liste.append(dico_peak[k+9])\n","            liste.append(dico_peak[k+10])\n","            liste.append(dico_peak[k+11])\n","            \n","            liste.append(dico_peak[k+12])\n","            liste.append(dico_peak[k+13])\n","            liste.append(dico_peak[k+14])\n","            liste.append(dico_peak[k+15])\n","    \n","      k=k+16\n","      dico_how_to_group[i]=liste\n","      i=i+1\n","      liste=[]\n","      \n","    \n","  if beats_division==3:\n","    while (k+3)<=(len(dico_peak)-1):\n","    \n","      liste.append(dico_peak[k])\n","      liste.append(dico_peak[k+1])\n","      liste.append(dico_peak[k+2])\n","      liste.append(dico_peak[k+3])\n","      if (k+3)==(len(dico_peak)-1):\n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        \n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","        liste.append(0)\n","      else:\n","        if (k+7)==(len(dico_peak)-1):\n","          liste.append(dico_peak[k+4])\n","          liste.append(dico_peak[k+5])\n","          liste.append(dico_peak[k+6])\n","          liste.append(dico_peak[k+7])\n","          \n","          liste.append(0)\n","          liste.append(0)\n","          liste.append(0)\n","          liste.append(0)\n","        else:\n","          liste.append(dico_peak[k+4])\n","          liste.append(dico_peak[k+5])\n","          liste.append(dico_peak[k+6])\n","          liste.append(dico_peak[k+7])\n","          \n","          liste.append(dico_peak[k+8])\n","          liste.append(dico_peak[k+9])\n","          liste.append(dico_peak[k+10])\n","          liste.append(dico_peak[k+11])\n","      \n","      k=k+12\n","      dico_how_to_group[i]=liste\n","      i=i+1\n","      liste=[]\n","    \n","  \n","  return (dico_how_to_group)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GvG-1OO7UBFP","colab":{}},"source":["for i in idSALAMITest:\n","  val=i\n","  F=50\n","    \n","  y,sr=librosa.load('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI/'+str(i)+'.mp3')\n","  y_later_use=y\n","  proc = madmom.features.downbeats.DBNDownBeatTrackingProcessor(beats_per_bar=[3, 4], fps=100)\n","  act = madmom.features.downbeats.RNNDownBeatProcessor()(y)\n","  estimated = proc(act)\n","  beats = estimated[:,0]\n","  beats_frames=librosa.core.time_to_frames(beats, sr=sr*2)\n","  downbeats = beats[estimated[:,1]==1]\n","  downbeats_frames=librosa.core.time_to_frames(downbeats, sr=sr*2)\n","  \n","  \n","  o_env = librosa.onset.onset_strength(y, sr=sr,hop_length=512,aggregate=np.median)\n","  peaks = librosa.util.peak_pick(o_env, 3, 3, 3, 5, 0.5, 2) \n","  times = librosa.frames_to_time(np.arange(len(o_env)), sr=sr,hop_length=512)\n"," \n","   \n","  # Set the hop length; at 22050 Hz, 512 samples ~= 23ms\n","  hop_length = 512\n","\n","  # Separate harmonics and percussives into two waveforms\n","  y_harmonic, y_percussive = librosa.effects.hpss(y)\n"," \n","\n","  # Compute MFCC features from the raw signal\n","  mfccs = np.array([mfcc(spectrum(hamming_window(frame)))[1]\n","               for frame in ess.FrameGenerator(y, frameSize=frame_sz, hopSize=hop_sz)])\n","  mfccs = sklearn.preprocessing.scale(mfccs)\n","  \n","  beats_frames=np.insert(beats_frames,0, 0)\n","  beats_frames=np.append(beats_frames,len(mfccs)-1)\n","  \n","  \n","  if 0 not in downbeats_frames :\n","    downbeats_frames=np.insert(downbeats_frames,0, 0)\n","  if (len(mfccs)-1) not in downbeats_frames :\n","    downbeats_frames=np.append(downbeats_frames,len(mfccs)-1)\n","    \n","  \n","  if path.exists('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI_annotations/annotations/'+str(i)+'/parsed/textfile1_functions.txt'):\n","    txt1 = Path('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI_annotations/annotations/'+str(i)+'/parsed/textfile1_functions.txt').read_text()\n","    for t in txt1:\n","      if t!='0' and t!='1' and t!='2' and t!='3' and t!='4' and t!='5' and t!='6' and t!='7' and t!='8' and t!='9' and t!='.':\n","        txt1 = txt1.replace(t,' ')\n","    annot_s1=txt1.split()\n","    annot_sec1=list(map(float, annot_s1))\n","    annot_frames1=librosa.core.time_to_frames(annot_sec1, sr=sr)\n","    liste1=trouver_la_liste(downbeats_frames,annot_frames1)\n","    \n","  else:\n","    liste1=[]\n","  \n","  if path.exists('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI_annotations/annotations/'+str(i)+'/parsed/textfile2_functions.txt'):\n","    txt2 = Path('/content/drive/My Drive/Colab Notebooks/PFE/SALAMI_annotations/annotations/'+str(i)+'/parsed/textfile2_functions.txt').read_text()   \n","    for t in txt2:\n","      if t!='0' and t!='1' and t!='2' and t!='3' and t!='4' and t!='5' and t!='6' and t!='7' and t!='8' and t!='9' and t!='.':\n","        txt2 = txt2.replace(t,' ')\n","    annot_s2=txt2.split()\n","    annot_sec2=list(map(float, annot_s2))\n","    annot_frames2=librosa.core.time_to_frames(annot_sec2, sr=sr)\n","    liste2=trouver_la_liste(downbeats_frames,annot_frames2)\n","    \n","  else:\n","    liste2=[]  \n","\n","  \n","  beat_mfcc=librosa.util.sync(mfccs.T,beats_frames)\n","  \n","  downbeat_mfcc=how_to_group_dico_mfcc(downbeats_frames, beat_mfcc)\n","\n","  # Compute chroma features from the harmonic signal\n","  chromagram = librosa.feature.chroma_cqt(y=y_harmonic,\n","                                        sr=sr)\n","\n","  # Aggregate chroma features between beat events\n","  # We'll use the median value of each feature between beat frames\n","  beat_chroma = librosa.util.sync(chromagram,\n","                                beats_frames,\n","                                aggregate=np.median)\n","  \n","  downbeat_chromas=how_to_group_chromas(downbeats_frames, beat_chroma)\n","\n","  R_aff_chroma = librosa.segment.recurrence_matrix(downbeat_chromas, mode='affinity',metric='cosine',self=True,axis=0)\n","  R_aff_mfcc = librosa.segment.recurrence_matrix(downbeat_mfcc, mode='affinity',metric='cosine',self=True,axis=0)\n","  \n","  \n","  R_aff_chroma=np.pad(R_aff_chroma, (25,25), 'constant', constant_values=(0, 0))\n","  R_aff_mfcc=np.pad(R_aff_mfcc, (25,25), 'constant', constant_values=(0, 0))\n","  \n","  \n","  listefusion=liste1\n","  for i in range (len(liste2)):\n","    if liste2[i] not in liste1:\n","      listefusion.append(liste2[i])    \n","  \n","  dico_sousmatrice_SMJ1={}\n","  for k in range (int(F/2),int(len(R_aff_chroma)-F/2)):\n","    m= np.zeros((F,F))\n","    for x in range (0,F-1):\n","      for y in range (0,F-1):\n","        m[x][y]=R_aff_chroma[int(x+(k-F/2))][int(y+(k-F/2))]\n","              \n","    dico_sousmatrice_SMJ1[k-int(F/2)]=m\n","    \n","    \n","  dico_sousmatrice_SMJ2={}\n","  for k in range (int(F/2),int(len(R_aff_chroma)-F/2)):\n","    m= np.zeros((F,F))\n","    for x in range (0,F-1):\n","      for y in range (0,F-1):\n","        m[x][y]=R_aff_mfcc[int(x+(k-F/2))][int(y+(k-F/2))]\n","              \n","    dico_sousmatrice_SMJ2[k-int(F/2)]=m \n","    \n"," \n","  #partie où on sauve avec chromas&mfcss\n","  cl=np.zeros((50,50))\n","  cl=Image.fromarray(np.uint8(cl*255), 'L')\n","  for j in range(len(dico_sousmatrice_SMJ1)):\n","    im1=dico_sousmatrice_SMJ1[j]\n","    im2=dico_sousmatrice_SMJ2[j]\n","    im_chroma=Image.fromarray(np.uint8(im1*255), 'L')\n","    im_mfcc=Image.fromarray(np.uint8(im2*255), 'L')\n","    merged=Image.merge(\"RGB\",(cl, im_mfcc, im_chroma))\n","    \n","    if j in listefusion:\n","      merged.save('/content/drive/My Drive/Colab Notebooks/Salami preprocessing_downbeatsync/SSMs_without_metergram/Test/Test/SSM_segment_sousmatrice'+str(val)+'_'+str(j)+'.jpeg')\n","    else:\n","      merged.save('/content/drive/My Drive/Colab Notebooks/Salami preprocessing_downbeatsync/SSMs_without_metergram/Test/Test/SSM_sousmatrice'+str(val)+'_'+str(j)+'.jpeg')\n","       \n","  \n","  #part specific for the metergram:\n","  \n"," \n","  l=decoupe_beats_in4parts(beats_frames)\n","  dico_peak2=get_dico_peaks(l, peaks, o_env)\n","  dico_how_to_group2=how_to_group_dico_subdiv4(downbeats_frames, dico_peak2)\n","\n","  orderedNames=[]\n","  for key in sorted(dico_how_to_group2):\n","    orderedNames.append(key)\n"," \n","  dataMatrix = np.array([dico_how_to_group2[i] for i in orderedNames])\n","  #M=dataMatrix.T\n","  \n","  R_aff_meter = librosa.segment.recurrence_matrix(dataMatrix, mode='affinity',metric='cosine',self=True,axis=0)\n","  R_aff_meter = np.pad(R_aff_meter, (25,25), 'constant', constant_values=(0, 0))\n","  \n","  \n","  dico_sousmatrice_SMJ3={}\n","  for k in range (int(F/2),int(len(R_aff_chroma)-F/2)):\n","    m= np.zeros((F,F))\n","    for x in range (0,F-1):\n","      for y in range (0,F-1):\n","        m[x][y]=R_aff_meter[int(x+(k-F/2))][int(y+(k-F/2))]\n","              \n","    dico_sousmatrice_SMJ3[k-int(F/2)]=m\n","    \n","    \n","  #partie où on sauve avec le metergram en plus:\n","  \n","  for j in range(len(dico_sousmatrice_SMJ1)):\n","    im1=dico_sousmatrice_SMJ1[j]\n","    im2=dico_sousmatrice_SMJ2[j]\n","    im3=dico_sousmatrice_SMJ3[j]\n","    im_chroma=Image.fromarray(np.uint8(im1*255), 'L')\n","    im_mfcc=Image.fromarray(np.uint8(im2*255), 'L')\n","    im_meter=Image.fromarray(np.uint8(im3*255), 'L')\n","    merged=Image.merge(\"RGB\",(im_meter, im_mfcc, im_chroma))\n","    \n","    \n","    if j in listefusion:\n","      merged.save('/content/drive/My Drive/Colab Notebooks/Salami preprocessing_downbeatsync/SSMs_with_metergram/Test/Test/SSM_segment_sousmatrice'+str(val)+'_'+str(j)+'.jpeg')\n","    else:\n","      merged.save('/content/drive/My Drive/Colab Notebooks/Salami preprocessing_downbeatsync/SSMs_with_metergram/Test/Test/SSM_sousmatrice'+str(val)+'_'+str(j)+'.jpeg')\n","          \n","  \n","  mel=librosa.feature.melspectrogram(y=y_later_use, sr=sr,n_mels=80)\n","  beat_mel = librosa.util.sync(mel,downbeats_frames)\n","  b_m=librosa.power_to_db(beat_mel,ref=np.max)\n","  \n","  mel_padded=np.zeros(shape=(80,len(b_m.T)+F)) \n","\n","  for i in range(len(b_m)):\n","    x=np.insert(b_m[i], 0, -70*np.ones(25))\n","    x=np.append(x,-70*np.ones(25))\n","    mel_padded[i]=x\n","    \n","  t_m=mel_padded.T\n","  dico_sousmatrice_melspectro={}\n","  for k in range (int(F/2),int(len(mel_padded.T)-F/2)):\n","  \n","    m= np.zeros(shape=(F,80))\n","    for x in range (0,F):\n","      \n","        m[x]=t_m[int(x+(k-F/2))]\n","        \n","    m=m.T          \n","    dico_sousmatrice_melspectro[k-int(F/2)]=m        \n","  \n","  \n","  #partie où on sauve melspectrog\n","  for i in range(len(dico_sousmatrice_melspectro)):\n","    OL=dico_sousmatrice_melspectro[i]\n","    m=OL/(-80)\n","    im=Image.fromarray(np.uint8(m*255), 'L')\n","    \n","    if i in listefusion:\n","      im.save('/content/drive/My Drive/Colab Notebooks/Salami preprocessing_downbeatsync/melspectrog/Test/Test/melspect_segment_sousmatrice'+str(val)+'_'+str(i)+'.jpeg')\n","    else:\n","      im.save('/content/drive/My Drive/Colab Notebooks/Salami preprocessing_downbeatsync/melspectrog/Test/Test/melspect_sousmatrice'+str(val)+'_'+str(i)+'.jpeg')\n"," "],"execution_count":0,"outputs":[]}]}